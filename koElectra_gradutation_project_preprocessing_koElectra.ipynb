{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4X2liEESmwPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "#make new folder in drive\n",
        "new_folder_path = '/content/drive/My Drive/graduation2024'\n",
        "os.makedirs(new_folder_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "_FKeU9JGm4Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"/content/drive/My Drive/graduation2024\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ja3UWlpKnVgu",
        "outputId": "1254977c-98aa-43bb-f84a-9aaaae79041a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/graduation2024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SKplanet/Dialog-KoELECTRA.git"
      ],
      "metadata": {
        "id": "Isxww8UEngxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "ei-dXk4ezMIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tokeninzer 수정 위해 기존 KoElectra Vocab에 단어 추가 - '파이썬'만 추가\n"
      ],
      "metadata": {
        "id": "fvRtOESsfD3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install autocorrect # 오타 교정"
      ],
      "metadata": {
        "id": "6BfqoGTsArvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install googletrans==4.0.0-rc1 # 언어 통일(papagoAPI 대용)"
      ],
      "metadata": {
        "id": "YJNFGX0HJSP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autocorrect import Speller # 오타 교정\n",
        "# maek => make\n",
        "import requests\n",
        "import googletrans # 번역\n",
        "\n",
        "def fix_typo(sentence, language): # 오타 교정\n",
        "  spell = Speller(lang=language)\n",
        "\n",
        "  # split the sentence into words\n",
        "  words = sentence.split()\n",
        "\n",
        "  # find and fix typo\n",
        "  correct_words = [spell(word)+' ' for word in words]\n",
        "\n",
        "  # make a sentence\n",
        "  correct_sentence = ''.join(correct_words)\n",
        "  return correct_sentence\n",
        "\n",
        "\n",
        "# 타 언어 제거, 번역\n",
        "# using 파이썬 modify this code => using python modify this code\n",
        "\n",
        "def mono_lang(sentence, language): # input sentence, 'en', 'ko' ...etc\n",
        "  # general translation\n",
        "  source_lang = 'ko'\n",
        "  target_lang = language\n",
        "  text = sentence\n",
        "\n",
        "  # papago API\n",
        "  client_id = 'EMmKltfYKVWFG61jU5OW'\n",
        "  client_secret = 'i5npjLvENG'\n",
        "\n",
        "  # API 엔드포인트 및 헤더 설정\n",
        "  url = 'https://openapi.naver.com/v1/papago/n2mt'\n",
        "  headers = {\n",
        "      'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',\n",
        "      'X-Naver-Client-Id': client_id,\n",
        "      'X-Naver-Client-Secret': client_secret,\n",
        "  }\n",
        "\n",
        "  # en, ko, 번역 텍스트\n",
        "  data = {\n",
        "      'source': source_lang,\n",
        "      'target': target_lang,\n",
        "      'text': text,\n",
        "  }\n",
        "\n",
        "  # API 요청\n",
        "  response = requests.post(url, headers=headers, data=data)\n",
        "\n",
        "  # JSON 응답 파싱\n",
        "  result = response.json()\n",
        "\n",
        "  # 번역된 텍스트 반환\n",
        "  translated_text = result['message']['result']['translatedText']\n",
        "  print('1차 번역 :',translated_text) # 한->영\n",
        "\n",
        "  data = {\n",
        "      'source': target_lang,\n",
        "      'target': source_lang,\n",
        "      'text': translated_text,\n",
        "  }\n",
        "\n",
        "  # API 요청2\n",
        "  response = requests.post(url, headers=headers, data=data)\n",
        "\n",
        "  # JSON 응답 파싱2\n",
        "  result = response.json()\n",
        "\n",
        "  translated_text = result['message']['result']['translatedText']\n",
        "  print('2차 번역 :',translated_text) # 영->한\n",
        "\n",
        "  return translated_text\n"
      ],
      "metadata": {
        "id": "BfIlsc94vG9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def detokenize(tokens): # 띄어쓰기 제공\n",
        "    words = []\n",
        "    current_word = \"\"\n",
        "    for token in tokens:\n",
        "        if token.startswith(\"##\"):\n",
        "            current_word += token[2:]\n",
        "        else:\n",
        "            if current_word:\n",
        "                words.append(current_word)\n",
        "            current_word = token\n",
        "\n",
        "    if current_word:\n",
        "        words.append(current_word)\n",
        "\n",
        "    return \" \".join(words)\n",
        "\n",
        "\n",
        "def sentence_split_generate(input_text):\n",
        "  result = tokenizer.tokenize(input_text)\n",
        "  print('result : ', result)\n",
        "  # ['', '[CLS]', '1', '##에', '##서', '10', '##까', '##지', '더', '##하', '##고', ',', '그', '값', '##을', '10', '##으로', '나누', '##는', '파이', '##썬', '코드', '##를', '만들', '##어', '##줘', '.']\n",
        "\n",
        "\n",
        "# 문장의 목적을 따로 분류하도록 모델을 fine-tuning시켜 강조?\n",
        "\n",
        "\n",
        "  return_sentence = []\n",
        "  current_sent = \"\"\n",
        "\n",
        "  remove_point = ['[CLS]', '[SEP]']\n",
        "\n",
        "  for word in result:\n",
        "\n",
        "    if word in remove_point: # 앞뒤 CLS, SEP 삭제\n",
        "      continue\n",
        "\n",
        "  final_result = detokenize(result) # 띄어쓰기 포함해서 문장 합치기\n",
        "\n",
        "  # if word.endswith('.') or word.endswith(','): # .나 ,로 문장에 줄바꿈\n",
        "  #   return_sentence.append(current_sent.strip())\n",
        "  #   current_sent = \"\"\n",
        "  # print('return : ', return_sentence)\n",
        "  return final_result\n",
        "\n",
        "def generate_custom_sentence(prompt, max_length=50, temperature=1.0): # dialog-koelectra이용해 문장 이쁘게 다듬기(최종)\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "    output_ids = model.generate(input_ids, max_length=max_length, temperature=temperature, num_beams=5)\n",
        "    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "    return generated_text\n"
      ],
      "metadata": {
        "id": "N_amm3p8_aoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ElectraTokenizer, ElectraForSequenceClassification\n",
        "import torch\n",
        "\n",
        "\n",
        "# chatGPT 프롬프트가 대화형이므로 한국어 대화형에 최적화된 모델인 skplanet - dialog-koElectra를 사용\n",
        "tokenizer = ElectraTokenizer.from_pretrained(\"skplanet/dialog-koelectra-small-discriminator\")\n",
        "model = ElectraForSequenceClassification.from_pretrained(\"skplanet/dialog-koelectra-small-discriminator\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBAOSXGzodhG",
        "outputId": "eb424f4e-216b-419d-ee9d-19d9b1e61c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at skplanet/dialog-koelectra-small-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## main ##\n",
        "\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# 랜덤 시드\n",
        "set_seed(42)\n",
        "\n",
        "#update tokenizer process\n",
        "add_token_num = tokenizer.add_tokens(['파이썬'])# add token in vocab\n",
        "\n",
        "# update tokenizer\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Sentence to be paraphrased => 여기를 input값으로 수정하면 됨!!\n",
        "input_sentence = \"chatGPT가 짜준 코드를 웹크롤링해서 불러온 다음에, 컴파일러에 실행시키고 오류를 재귀적으로 고쳐서 완벽한 코드를 만드는 파이썬 코드를 알려줘 \" # => make a python code which adds from 1 to 10 (이정도까지 오타가 나진 않을거같긴함)\n",
        "\n",
        "# Tokenize the sentence / preprocessing\n",
        "language = 'en' # target language\n",
        "fixed_typo_sentence = fix_typo(input_sentence, language) # 특수문자, 오타, 타 언어, 띄어쓰기 교정\n",
        "print(\"오타 교정 : \",fixed_typo_sentence)\n",
        "fixed_language = mono_lang(fixed_typo_sentence, language) # 타 언어 제거 - (input언어가 한국어인 경우만 상정) 파파고 api 이용->번역 2회\n",
        "print('언어 통일 : ', fixed_language)\n",
        "\n",
        "# conjunctions = ['그리고', '또한']  # 문장 분할시 추가 접속사들\n",
        "\n",
        "fixed_lang = sentence_split_generate(fixed_language) # 문장 분할해서 새 문장 생성(줄바꿈)\n",
        "print(\"문장 분할 : \",fixed_lang)\n",
        "\n",
        "\n",
        "# 추가 문맥제공, 강조, trigger sentence 추가 / 문맥, 강조 후에 추가\n",
        "trigger_sent = \"\\n이 과정을 순서대로 알려줘\" # 변형 가능 // process in order / print in order . . .\n",
        "\n",
        "# gui를 사용해 맥락 제공 -> 맥락에 맞는 버튼을 눌러서 트리거 문장 추가\n",
        "triggerSentences = ['이 과정을 순서대로 알려줘.',\n",
        "                    '맞춤법이 틀린 부분을 수정해줘.',\n",
        "                    '모든 코드에 주석을 달아줘.'] # 추가될 수 있음\n",
        "\n",
        "final_output = fixed_lang + trigger_sent\n",
        "\n",
        "\n",
        "# 문장 분할된 값을 모델에 넣어서 문장 이쁘게 다듬기\n",
        "print(\"\\nfinal output using dialog-koElectra : \", final_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2IzdrAs3sOc",
        "outputId": "261b569e-f828-45f6-c3c9-3c6366fed6fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오타 교정 :  chatGPT가 짜준 코드를 웹크롤링해서 불러온 다음에, 컴파일러에 실행시키고 오류를 재귀적으로 고쳐서 완벽한 코드를 만드는 파이썬 코드를 알려줘 \n",
            "1차 번역 : After webcrolling the code that chatGPT put together, let me know the Python code that makes perfect code by executing it in the compiler and recursively correcting errors\n",
            "2차 번역 : chatGPT들이 정리한 코드를 웹 크롤링한 후 컴파일러에서 실행하여 오류를 재귀적으로 수정하여 완벽한 코드를 만드는 파이썬 코드를 알려주세요\n",
            "언어 통일 :  chatGPT들이 정리한 코드를 웹 크롤링한 후 컴파일러에서 실행하여 오류를 재귀적으로 수정하여 완벽한 코드를 만드는 파이썬 코드를 알려주세요\n",
            "result :  ['c', '##ha', '##t', '##G', '##P', '##T', '##들이', '정리', '##한', '코드', '##를', '웹', '크', '##롤', '##링', '##한', '후', '컴', '##파일', '##러', '##에서', '실행', '##하', '##여', '오류', '##를', '재', '##귀', '##적', '##으로', '수정', '##하', '##여', '완벽', '##한', '코드', '##를', '만드', '##는', '파이썬', '코드', '##를', '알려', '##주세요']\n",
            "문장 분할 :  chatGPT들이 정리한 코드를 웹 크롤링한 후 컴파일러에서 실행하여 오류를 재귀적으로 수정하여 완벽한 코드를 만드는 파이썬 코드를 알려주세요\n",
            "\n",
            "final output using dialog-koElectra :  chatGPT들이 정리한 코드를 웹 크롤링한 후 컴파일러에서 실행하여 오류를 재귀적으로 수정하여 완벽한 코드를 만드는 파이썬 코드를 알려주세요\n",
            "이 과정을 순서대로 알려줘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "@misc{DialogKoELECTRA,\n",
        "  author       = {Wonchul Kim and Junseok Kim and Okkyun Jeong},\n",
        "  title        = {Dialog-KoELECTRA: Korean conversational language model based on ELECTRA model},\n",
        "  howpublished = {\\url{https://github.com/skplanet/Dialog-KoELECTRA}},\n",
        "  year         = {2021},\n",
        "}"
      ],
      "metadata": {
        "id": "IHmf9SfToT3J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "openai API\n",
        "\n"
      ],
      "metadata": {
        "id": "hXmt5IHoPacJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# OpenAI API 키 설정\n",
        "openai.api_key = 'YOUR_API_KEY'\n",
        "\n",
        "def prompt_engineering(prompt, max_tokens=50, temperature=0.7):\n",
        "    # GPT 모델에 입력할 prompt 설정\n",
        "    input_prompt = f\"프롬프트 엔지니어링: {prompt}\"\n",
        "\n",
        "    # OpenAI API 호출\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-002\",  # 적절한 엔진 선택\n",
        "        prompt=input_prompt,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature\n",
        "    )\n",
        "\n",
        "    # 생성된 텍스트 반환\n",
        "    return response['choices'][0]['text'].strip()\n",
        "\n",
        "# 프롬프트 엔지니어링을 테스트할 문장\n",
        "input_sentence = \"인공지능에 대해 설명해봐.\"\n",
        "\n",
        "# 프롬프트 엔지니어링 함수 호출\n",
        "output_sentence = prompt_engineering(input_sentence)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"입력 문장: {input_sentence}\")\n",
        "print(f\"프롬프트 엔지니어링 결과: {output_sentence}\")\n"
      ],
      "metadata": {
        "id": "hdNJWB9LCER-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<!-- # @misc{DialogKoELECTRA,\n",
        "#   author       = {Wonchul Kim and Junseok Kim and Okkyun Jeong},\n",
        "#   title        = {Dialog-KoELECTRA: Korean conversational language model based on ELECTRA model},\n",
        "#   howpublished = {\\url{https://github.com/skplanet/Dialog-KoELECTRA}},\n",
        "#   year         = {2021},\n",
        "# } -->"
      ],
      "metadata": {
        "id": "wWlVo31PoO3T"
      }
    }
  ]
}